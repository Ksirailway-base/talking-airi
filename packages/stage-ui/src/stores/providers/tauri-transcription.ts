import type { TranscriptionProvider } from '@xsai-ext/shared-providers'
import { invoke } from '@tauri-apps/api/core'

// –†–∞—Å—à–∏—Ä—è–µ–º –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å Window –¥–ª—è –ø–æ–¥–¥–µ—Ä–∂–∫–∏ Tauri
declare global {
  interface Window {
    __TAURI__?: any
  }
}

export interface TauriTranscriptionOptions {
  model?: string
}

export interface WhisperModel {
  id: string
  name: string
  size: string
  url: string
}

// –î–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏ Whisper
export const WHISPER_MODELS: WhisperModel[] = [
  {
    id: 'whisper-tiny',
    name: 'Whisper Tiny',
    size: '39 MB',
    url: 'https://huggingface.co/ggerganov/whisper.cpp/resolve/main/ggml-tiny.bin'
  },
  {
    id: 'whisper-base',
    name: 'Whisper Base', 
    size: '142 MB',
    url: 'https://huggingface.co/ggerganov/whisper.cpp/resolve/main/ggml-base.bin'
  },
  {
    id: 'whisper-small',
    name: 'Whisper Small',
    size: '466 MB', 
    url: 'https://huggingface.co/ggerganov/whisper.cpp/resolve/main/ggml-small.bin'
  }
]

export function createTauriTranscription(options: TauriTranscriptionOptions = {}): TranscriptionProvider {
  const modelId = options.model || 'whisper-tiny'
  
  return {
    transcription: (model: string) => ({
      baseURL: 'tauri://localhost',
      model: model || modelId,
      transcribe: async (audio: ArrayBuffer) => {
        try {
          // –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –º—ã –≤ Tauri –æ–∫—Ä—É–∂–µ–Ω–∏–∏
          if (typeof window === 'undefined' || !window.__TAURI__) {
            throw new Error('Tauri –æ–∫—Ä—É–∂–µ–Ω–∏–µ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–æ')
          }
          
          // –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å –µ—Å–ª–∏ –µ—â–µ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞
          await invoke('plugin:ipc-audio-transcription-ort|load_ort_model_whisper', {
            modelType: modelId as 'base' | 'largev3' | 'tiny' | 'medium'
          })
          
          // –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º ArrayBuffer –≤ Uint8Array
          const audioData = new Uint8Array(audio)
          
          // –í—ã–∑—ã–≤–∞–µ–º —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—é —á–µ—Ä–µ–∑ Tauri
          const result = await invoke('plugin:ipc-audio-transcription-ort|ipc_audio_transcription', {
            chunk: Array.from(audioData),
            language: 'auto'
          })
          
          return {
            text: result as string
          }
        } catch (error) {
          console.error('–û—à–∏–±–∫–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ Whisper:', error)
          throw new Error(`–û—à–∏–±–∫–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏: ${error}`)
        }
      }
    })
  }
}

// –§—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏ Whisper
export async function loadWhisperModel(modelId: string): Promise<void> {
  try {
    // –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –º—ã –≤ Tauri –æ–∫—Ä—É–∂–µ–Ω–∏–∏
    if (typeof window !== 'undefined' && window.__TAURI__) {
      await invoke('plugin:ipc-audio-transcription-ort|load_ort_model_whisper', {
        modelType: modelId as 'base' | 'largev3' | 'tiny' | 'medium'
      })
    } else {
      console.warn('Tauri –æ–∫—Ä—É–∂–µ–Ω–∏–µ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–æ, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –∑–∞–≥—Ä—É–∑–∫—É –º–æ–¥–µ–ª–∏ Whisper')
    }
  } catch (error) {
    console.error('–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏ Whisper:', error)
    throw new Error(`–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: ${error}`)
  }
}

// –§—É–Ω–∫—Ü–∏—è –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏ Whisper Tiny –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –∑–∞–ø—É—Å–∫–µ
export async function initializeWhisperModel(): Promise<void> {
  try {
    // –ó–∞–≥—Ä—É–∂–∞–µ–º —Å–∞–º—É—é –º–∞–ª–µ–Ω—å–∫—É—é –º–æ–¥–µ–ª—å Whisper Tiny –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
    await loadWhisperModel('tiny')
    console.log('–ú–æ–¥–µ–ª—å Whisper Tiny —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞')
  } catch (error) {
    console.warn('–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å Whisper Tiny:', error)
    // –ù–µ –≤—ã–±—Ä–∞—Å—ã–≤–∞–µ–º –æ—à–∏–±–∫—É, —á—Ç–æ–±—ã –Ω–µ –±–ª–æ–∫–∏—Ä–æ–≤–∞—Ç—å –∑–∞–ø—É—Å–∫ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
  }
}

// –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Å–ø–∏—Å–∫–∞ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
export function getAvailableWhisperModels(): WhisperModel[] {
  return WHISPER_MODELS
}

// –§—É–Ω–∫—Ü–∏—è –¥–ª—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ WAV ArrayBuffer –≤ Float32Array
function wavToFloat32Array(wavBuffer: ArrayBuffer): Float32Array {
  const view = new DataView(wavBuffer)
  
  // –ü—Ä–æ–≤–µ—Ä—è–µ–º WAV –∑–∞–≥–æ–ª–æ–≤–æ–∫
  const riff = String.fromCharCode(view.getUint8(0), view.getUint8(1), view.getUint8(2), view.getUint8(3))
  if (riff !== 'RIFF') {
    throw new Error('Invalid WAV file: missing RIFF header')
  }
  
  // –ß–∏—Ç–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã WAV —Ñ–∞–π–ª–∞
  const numChannels = view.getUint16(22, true)
  const sampleRate = view.getUint32(24, true)
  const bitsPerSample = view.getUint16(34, true)
  const dataOffset = 44 // –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π —Ä–∞–∑–º–µ—Ä WAV –∑–∞–≥–æ–ª–æ–≤–∫–∞
  
  console.log('WAV file info:', { numChannels, sampleRate, bitsPerSample, dataOffset })
  
  // –í—ã—á–∏—Å–ª—è–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—ç–º–ø–ª–æ–≤
  const dataSize = view.getUint32(40, true)
  const numSamples = dataSize / (bitsPerSample / 8)
  
  // –°–æ–∑–¥–∞–µ–º Float32Array –¥–ª—è –∞—É–¥–∏–æ –¥–∞–Ω–Ω—ã—Ö
  const audioData = new Float32Array(numSamples)
  
  // –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º 16-bit PCM –≤ Float32
  for (let i = 0; i < numSamples; i++) {
    const sample = view.getInt16(dataOffset + i * 2, true)
    audioData[i] = sample / 32768.0 // –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –≤ –¥–∏–∞–ø–∞–∑–æ–Ω [-1, 1]
  }
  
  return audioData
}

// –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø—Ä—è–º–æ–π —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ –∞—É–¥–∏–æ
export async function transcribeAudio(audio: ArrayBuffer): Promise<string> {
  try {
    console.log('üé§ Starting transcription...', {
      audioBufferSize: audio.byteLength,
      audioType: 'WAV ArrayBuffer'
    })
    
    // –ù–ï –∑–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å –∑–¥–µ—Å—å, —Ç–∞–∫ –∫–∞–∫ –æ–Ω–∞ —É–∂–µ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –≤ index.vue
    console.log('üé§ Using pre-loaded Whisper model...')
    
    // –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º WAV ArrayBuffer –≤ Float32Array
    console.log('üé§ Converting WAV to Float32Array...')
    const audioData = wavToFloat32Array(audio)
    console.log('üé§ Audio conversion completed:', {
      samplesCount: audioData.length,
      durationSeconds: audioData.length / 16000,
      sampleRate: 16000
    })
    
    // –í—ã–∑—ã–≤–∞–µ–º —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—é —á–µ—Ä–µ–∑ Tauri
    console.log('üé§ Calling Tauri transcription...')
    const result = await invoke('plugin:ipc-audio-transcription-ort|ipc_audio_transcription', {
      chunk: Array.from(audioData),
      language: null // –ò—Å–ø–æ–ª—å–∑—É–µ–º –∞–≤—Ç–æ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —è–∑—ã–∫–∞ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
    })
    
    console.log('üé§ Transcription completed:', {
      result: result as string,
      length: (result as string)?.length || 0
    })
    
    return result as string
  } catch (error) {
    console.error('üé§ –û—à–∏–±–∫–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ Whisper:', error)
    throw new Error(`–û—à–∏–±–∫–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏: ${error}`)
  }
}